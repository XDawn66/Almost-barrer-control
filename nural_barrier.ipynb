{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1331.0923,  860.7158,  156.6412,   10.0000])\n",
      "tensor([1322.6477,  855.3596,  147.6138,   10.0000])\n"
     ]
    }
   ],
   "source": [
    "with open(\"data/safe_data_set.pkl\", \"rb\") as f:\n",
    "    safe_data = pickle.load(f)  # Load the Pickle file\n",
    "\n",
    "# Convert to PyTorch tensor\n",
    "safe_data = torch.tensor(safe_data, dtype=torch.float32)\n",
    "# Use safe data in training\n",
    "states_safe = safe_data  # Use this in your training loop\n",
    "\n",
    "with open(\"data/unsafe_data_set.pkl\", \"rb\") as f2:\n",
    "    unsafe_data = pickle.load(f2)  # Load the Pickle file\n",
    "\n",
    "unsafe_data = torch.tensor(unsafe_data, dtype=torch.float32)\n",
    "states_unsafe = unsafe_data\n",
    "next_states_safe = states_safe[1:]  # All but the first state\n",
    "states_safe = states_safe[:-1]  # All but the last state\n",
    "print(states_safe[3])\n",
    "print(next_states_safe[3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BarrierFunctionNet(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(BarrierFunctionNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, 256)\n",
    "        self.fc2 = nn.Linear(256, 1)\n",
    "        self.tanh = nn.Tanh()\n",
    "\n",
    "    def forward(self, x):\n",
    "        hidden = self.tanh(self.fc1(x))\n",
    "        return self.fc2(hidden)  # Now matches the passage's full equation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def phi(x):\n",
    "    \"\"\"ReLU function to enforce barrier constraints.\"\"\"\n",
    "    return torch.maximum(x, torch.tensor(0.0))\n",
    "\n",
    "def barrier_loss(B_s, B_u, Lf_B_s, gamma, ws=1.0, wu=1.0, wl=1.0):\n",
    "    \"\"\"\n",
    "    Computes the barrier function loss L(θ).\n",
    "\n",
    "    Args:\n",
    "        B_s: Barrier function output for safe states (Tensor of shape [Ns]).\n",
    "        B_u: Barrier function output for unsafe states (Tensor of shape [Nu]).\n",
    "        Lf_B_s: Lie derivative of B(x) for safe states (Tensor of shape [Ns]).\n",
    "        gamma: Weight for the Lie derivative constraint.\n",
    "        ws, wu, wl: Weights for different loss terms.\n",
    "\n",
    "    Returns:\n",
    "        Total loss value.\n",
    "    \"\"\"\n",
    "    Ns = B_s.shape[0]  # Number of safe samples\n",
    "    Nu = B_u.shape[0]  # Number of unsafe samples\n",
    "\n",
    "    # Compute each term of the loss\n",
    "    loss_safety = ws * torch.mean(phi(-B_s))   # First term\n",
    "    loss_usability = wu * torch.mean(phi(B_u)) # Second term\n",
    "    loss_invariance = wl * torch.mean(phi(-Lf_B_s - gamma * B_s))  # Third term\n",
    "\n",
    "    # Combine the terms\n",
    "    total_loss = loss_safety + loss_usability + loss_invariance\n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_Lf_B_approx(barrier_net, states, next_states, delta_t):\n",
    "    \"\"\"\n",
    "    Approximates the Lie derivative Lf B(x) using sampled trajectories.\n",
    "\n",
    "    Args:\n",
    "        barrier_net: Neural network for the barrier function.\n",
    "        states: Current states (Tensor of shape [Ns, state_dim]).\n",
    "        next_states: Next states (Tensor of shape [Ns, state_dim]).\n",
    "        delta_t: Time difference between consecutive states.\n",
    "\n",
    "    Returns:\n",
    "        Approximation of Lf B(x).\n",
    "    \"\"\"\n",
    "    # Compute B(s) and B(s0)\n",
    "    B_s = barrier_net(states)\n",
    "    B_next = barrier_net(next_states)\n",
    "\n",
    "    # Approximation: (B(s0) - B(s)) / delta_t\n",
    "    Lf_B = (B_next - B_s) / delta_t\n",
    "    return Lf_B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Zhenyu\\AppData\\Local\\Temp\\ipykernel_26000\\41853554.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load('checkpoint2.pth')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BarrierFunctionNet(\n",
       "  (fc1): Linear(in_features=4, out_features=256, bias=True)\n",
       "  (fc2): Linear(in_features=256, out_features=1, bias=True)\n",
       "  (tanh): Tanh()\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the saved checkpoint\n",
    "checkpoint = torch.load('checkpoint2.pth')\n",
    "\n",
    "# Reinitialize the model and optimizer\n",
    "barrier_net = BarrierFunctionNet(4)\n",
    "optimizer = Adam(barrier_net.parameters(), lr=1e-3)\n",
    "\n",
    "# Load the state_dict for the model and optimizer\n",
    "barrier_net.load_state_dict(checkpoint['model_state_dict'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "\n",
    "# Get the last epoch and loss if needed\n",
    "start_epoch = checkpoint['epoch']\n",
    "last_loss = checkpoint['loss']\n",
    "\n",
    "# Set the model to evaluation mode or training mode\n",
    "barrier_net.train()  # or barrier_net.eval() if you want to evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resuming training from epoch 3000 with loss: 0.0024752230383455753\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Zhenyu\\AppData\\Local\\Temp\\ipykernel_26000\\3277413962.py:23: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(checkpoint_path)\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameters\n",
    "input_dim = 4  # Example input dimension for state\n",
    "gamma = 1.0    # Weight for invariance term\n",
    "ws, wu, wl = 1.0, 1.0, 1.0  # Loss weights\n",
    "delta_t = 0.1  # Time step\n",
    "\n",
    "# Initialize the barrier function network and optimizer\n",
    "barrier_net = BarrierFunctionNet(input_dim)\n",
    "optimizer = Adam(barrier_net.parameters(), lr=1e-3)\n",
    "\n",
    "# Training data (replace with actual safe/unsafe state data)\n",
    "Ns, Nu = 20000, 20000  # Number of safe and unsafe samples\n",
    "\n",
    "\n",
    "# Initialize the barrier function network and optimizer\n",
    "barrier_net = BarrierFunctionNet(input_dim)\n",
    "optimizer = Adam(barrier_net.parameters(), lr=1e-3)\n",
    "\n",
    "# Check if a checkpoint exists and load it\n",
    "checkpoint_path = 'checkpoint2.pth'\n",
    "start_epoch = 0  # default start epoch if no checkpoint is found\n",
    "if os.path.exists(checkpoint_path):\n",
    "    checkpoint = torch.load(checkpoint_path)\n",
    "    barrier_net.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    start_epoch = checkpoint['epoch'] + 1  # Continue from the next epoch\n",
    "    print(f\"Resuming training from epoch {start_epoch} with loss: {checkpoint['loss']}\")\n",
    "\n",
    "# Training loop (starting from the right epoch)\n",
    "for epoch in range(start_epoch, 2000):\n",
    "    # Forward pass: Compute B(x) for safe and unsafe states\n",
    "    B_s = barrier_net(states_safe)\n",
    "    B_u = barrier_net(states_unsafe)\n",
    "\n",
    "    # Compute Lf B(x) approximation for safe states\n",
    "    Lf_B_s = compute_Lf_B_approx(barrier_net, states_safe, next_states_safe, delta_t)\n",
    "\n",
    "    # Compute the loss\n",
    "    loss = barrier_loss(B_s, B_u, Lf_B_s, gamma, ws, wu, wl)\n",
    "\n",
    "    # Backward pass and optimization\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f\"Epoch {epoch + 1}, Loss: {loss.item():.4f}\")\n",
    "\n",
    "    # Save model and optimizer state every 10 epochs\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        torch.save({\n",
    "            'epoch': epoch,  # current epoch\n",
    "            'model_state_dict': barrier_net.state_dict(),  # model parameters\n",
    "            'optimizer_state_dict': optimizer.state_dict(),  # optimizer parameters\n",
    "            'loss': loss.item(),  # last loss value\n",
    "        }, checkpoint_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify_safe_states(barrier_net, states_safe):\n",
    "    barrier_values = barrier_net(states_safe)  # Compute B(x) for all safe states\n",
    "    if torch.all(barrier_values >= 0):  # Check if B(x) >= 0 for all safe states\n",
    "        print(\"Condition 1 satisfied: B(x) >= 0 for all x in X_s\")\n",
    "        return True\n",
    "    else:\n",
    "        print(\"Condition 1 violated: B(x) is negative for some x in X_s\")\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify_unsafe_states(barrier_net, states_unsafe):\n",
    "    barrier_values = barrier_net(states_unsafe)  # Compute B(x) for all unsafe states\n",
    "    if torch.all(barrier_values < 0):  # Check if B(x) < 0 for all unsafe states\n",
    "        print(\"Condition 2 satisfied: B(x) < 0 for all x in X_u\")\n",
    "        return True\n",
    "    else:\n",
    "        print(\"Condition 2 violated: B(x) is non-negative for some x in X_u\")\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_grid_around_boundary(states, threshold=0.1, delta=0.05):\n",
    "    # Create a grid around the boundary where B(x) = 0\n",
    "    grid_states = []\n",
    "    \n",
    "    # Loop over each state in the list of states\n",
    "    for state in states:\n",
    "        # Convert state to a tensor if it's not already\n",
    "        state_tensor = torch.tensor(state, dtype=torch.float32)\n",
    "        \n",
    "        # Compute the barrier function for this state\n",
    "        barrier_value = barrier_net(state_tensor).mean().item()  # Take the mean of the output vector\n",
    "        \n",
    "        # If B(x) is near 0 (within threshold), create a grid around this state\n",
    "        if np.abs(barrier_value) < threshold:  \n",
    "            # Create a grid around this state within a range of delta\n",
    "            for dx in np.linspace(-delta, delta, num=5):\n",
    "                # Apply dx element-wise to each dimension of the state\n",
    "                grid_state = state + np.array([dx] * len(state))  # Add dx to each dimension of state\n",
    "                grid_states.append(grid_state.tolist())  # Ensure grid_state is a list\n",
    "                \n",
    "    # Convert grid states to a tensor and return\n",
    "    return torch.tensor(grid_states, dtype=torch.float32)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_grid_around_boundary2(barrier_net, states_safe, dynamics_model, threshold=0.1, delta=0.01):\n",
    "    \"\"\"\n",
    "    Create a grid around boundary states and compute Lie derivative bounds.\n",
    "\n",
    "    Args:\n",
    "        barrier_net (torch.nn.Module): Neural network representing the barrier function B(x).\n",
    "        states_safe (numpy array): Safe states (N x dim).\n",
    "        dynamics_model (function): Function that computes f(x) given a state.\n",
    "        threshold (float): Distance to define the boundary.\n",
    "        delta (float): Perturbation for finite difference estimation.\n",
    "\n",
    "    Returns:\n",
    "        grid_states (numpy array): Sampled states around the boundary.\n",
    "        Lf_B_bounds (list of tuples): List of (lower, upper) bounds for L_f B(x).\n",
    "    \"\"\"\n",
    "    n, dim = states_safe.shape  # Number of states and state dimensions\n",
    "\n",
    "    # Generate perturbations to create the grid\n",
    "    perturbations = np.random.uniform(-threshold, threshold, size=(n, dim))\n",
    "    grid_states = states_safe + perturbations  # Apply small shifts around safe states\n",
    "\n",
    "    Lf_B_bounds = []  # Store Lie derivative bounds for each grid state\n",
    "\n",
    "    for state in grid_states:\n",
    "        # Compute Jacobian of the dynamics using finite differences\n",
    "        J_f = np.zeros((dim, dim))  # Jacobian initialization\n",
    "        control_input = np.array([0.0, 0.0])\n",
    "        f_a = dynamics_model(state,control_input)  # Compute f(a)\n",
    "\n",
    "        for i in range(dim):\n",
    "            perturb = np.zeros(dim)\n",
    "            perturb[i] = delta  # Perturb only the i-th dimension\n",
    "            f_perturbed = dynamics_model(state + perturb,control_input)  # Compute f(a + δe_i)\n",
    "\n",
    "            # Finite difference approximation for ∂f/∂x_i\n",
    "            J_f[:, i] = (f_perturbed - f_a) / delta  \n",
    "\n",
    "        # Compute ∇B(x)\n",
    "        state_tensor = torch.tensor(state, dtype=torch.float32, requires_grad=True)\n",
    "        B_x = barrier_net(state_tensor)  # Compute B(x)\n",
    "        B_x.backward()  # Compute gradient ∇B\n",
    "        grad_B = state_tensor.grad.detach().numpy()\n",
    "\n",
    "        # Compute Lie derivative bounds using interval arithmetic\n",
    "        Lf_B_lower = np.dot(grad_B, np.min(J_f, axis=1))  # Lower bound\n",
    "        Lf_B_upper = np.dot(grad_B, np.max(J_f, axis=1))  # Upper bound\n",
    "\n",
    "        Lf_B_bounds.append((Lf_B_lower, Lf_B_upper))\n",
    "\n",
    "    return grid_states, Lf_B_bounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_lie_derivative(barrier_net, state, dynamics_model, delta_t=0.1, control_input=None):\n",
    "    if control_input is None:\n",
    "        control_input = np.array([0.0, 0.0])  # Default control input: [acceleration, steering] = [0, 0]\n",
    "    \n",
    "    state = np.array(state) \n",
    "    state_tensor = torch.tensor(state, dtype=torch.float32, requires_grad=True)\n",
    "    B_x = barrier_net(state_tensor)\n",
    "    \n",
    "    # If B(x) is a vector, take the mean or sum to get a scalar\n",
    "    B_x = B_x.mean() \n",
    "    \n",
    "    # Compute the gradient of B(x) with respect to the state\n",
    "    B_x.backward()  # Compute the gradient of B(x)\n",
    "    \n",
    "    # Detach state from the computation graph and compute next state\n",
    "    state_detached = state_tensor.detach()  # Detach from the computation graph\n",
    "    state_next = state_detached + delta_t * dynamics_model(state_detached.numpy(), control_input)  # Use detached state\n",
    "\n",
    "    \n",
    "    # Compute the change in barrier function based on the system dynamics\n",
    "    Lf_B = B_x.item()  # Get the scalar value of the barrier function\n",
    "    return Lf_B\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify_lie_derivative(barrier_net, grid_states, dynamics_model, delta_t=0.1):\n",
    "    default_control_input = np.array([0.0, 0.0])  # Example: [acceleration, steering] = [0, 0]\n",
    "    violating_states = []\n",
    "    for state in grid_states:\n",
    "        # Ensure state is a numpy array or a list\n",
    "        Lf_B = compute_lie_derivative(barrier_net, state, dynamics_model, delta_t, control_input=default_control_input)\n",
    "        \n",
    "        if Lf_B <= 0:\n",
    "            # print(f\"Condition 3 violated: L_f B(x) <= 0 at state {state}\")\n",
    "            violating_states.append(state)\n",
    "    print(f\"Condition 3 violated: for len of {len(violating_states)}\")\n",
    "    return violating_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dynamics_model(state, control_input):\n",
    "    if isinstance(state, torch.Tensor):\n",
    "        state_values = state.detach().numpy()  # Convert the tensor to a numpy array\n",
    "    else:\n",
    "        state_values = state  # If it's already a numpy array, use it directly\n",
    "    \n",
    "    # Unpack the state values\n",
    "    x, y, theta, v = state_values[0], state_values[1], state_values[2], state_values[3]\n",
    "    a, delta = control_input  # Extract control inputs (acceleration, steering angle)\n",
    "    #print(x,y)\n",
    "    L = 2.5  # Wheelbase length (for example)\n",
    "    \n",
    "    # Compute the next state using the dynamics equations\n",
    "    dx = v * np.cos(theta) # Change in x position\n",
    "    dy = v * np.sin(theta) # Change in y position\n",
    "    delta = (v / L) * np.tan(delta) # Change in heading (yaw rate)\n",
    "    dv = a  # Change in velocity (acceleration)\n",
    "    #print(f\"dx: {dx}, dy: {dy}, dtheta: {dtheta}, dv: {dv}\")\n",
    "    return np.array([dx, dy, delta, dv], dtype=float)  # Explicitly set the dtype to ensure consistent types\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Condition 1 violated: B(x) is negative for some x in X_s\n",
      "Condition 2 violated: B(x) is non-negative for some x in X_u\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Zhenyu\\AppData\\Local\\Temp\\ipykernel_26000\\60093956.py:20: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
      "  grid_states = states_safe + perturbations  # Apply small shifts around safe states\n",
      "C:\\Users\\Zhenyu\\AppData\\Local\\Temp\\ipykernel_26000\\60093956.py:33: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
      "  f_perturbed = dynamics_model(state + perturb,control_input)  # Compute f(a + δe_i)\n",
      "C:\\Users\\Zhenyu\\AppData\\Local\\Temp\\ipykernel_26000\\60093956.py:39: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  state_tensor = torch.tensor(state, dtype=torch.float32, requires_grad=True)\n",
      "C:\\Users\\Zhenyu\\AppData\\Local\\Temp\\ipykernel_26000\\3396284254.py:5: DeprecationWarning: __array__ implementation doesn't accept a copy keyword, so passing copy=False failed. __array__ must implement 'dtype' and 'copy' keyword arguments. To learn more, see the migration guide https://numpy.org/devdocs/numpy_2_0_migration_guide.html#adapting-to-changes-in-the-copy-keyword\n",
      "  state = np.array(state)\n",
      "C:\\Users\\Zhenyu\\AppData\\Local\\Temp\\ipykernel_26000\\3396284254.py:17: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
      "  state_next = state_detached + delta_t * dynamics_model(state_detached.numpy(), control_input)  # Use detached state\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Condition 3 violated: for len of 5\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Condition 1: Verify safe states\n",
    "verify_safe_states(barrier_net, states_safe)\n",
    "\n",
    "# Condition 2: Verify unsafe states\n",
    "verify_unsafe_states(barrier_net, states_unsafe)\n",
    "\n",
    "# Condition 3: Verify Lie derivative for boundary states\n",
    "grid_states, _ = create_grid_around_boundary2(barrier_net, states_safe, dynamics_model, threshold=0.1, delta=0.05)\n",
    "violating_states = verify_lie_derivative(barrier_net, grid_states, dynamics_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "def knn_labeling(states, labels, test_states, k=6):\n",
    "    # Fit kNN classifier on the states with known labels\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(states, labels)\n",
    "    \n",
    "    # Predict labels for the test states\n",
    "    predicted_labels = knn.predict(test_states)\n",
    "    \n",
    "    return predicted_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State tensor([ 397.6548,  852.4391, -122.5868,   10.0257], dtype=torch.float64): Label 1\n",
      "State tensor([ 393.6957,  861.6785, -112.6384,   10.0402], dtype=torch.float64): Label 1\n",
      "State tensor([ 401.0556,  855.4220, -116.1718,    9.9340], dtype=torch.float64): Label 1\n",
      "State tensor([ 398.4114,  865.0586, -106.2958,   10.0813], dtype=torch.float64): Label 1\n",
      "State tensor([397.2530, 875.1494, -96.3005,   9.9189], dtype=torch.float64): Label 1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Prepare training data (safe and unsafe states)\n",
    "training_states = np.vstack([states_safe, states_unsafe])  # Stack them together\n",
    "training_labels = np.array([1] * len(states_safe) + [0] * len(states_unsafe))  # Safe = 1, Unsafe = 0\n",
    "\n",
    "# Convert violating states into a NumPy array\n",
    "violating_states_np = np.array([state.detach().numpy() for state in violating_states])\n",
    "\n",
    "# Use kNN to predict the labels for the violating states\n",
    "violating_labels = knn_labeling(training_states, training_labels, violating_states_np)\n",
    "\n",
    "# Print out the labels for violating states\n",
    "for i, state in enumerate(violating_states):\n",
    "    print(f\"State {state}: Label {violating_labels[i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Condition 1 violated: B(x) is negative for some x in X_s\n",
      "Condition 2 violated: B(x) is non-negative for some x in X_u\n",
      "Resuming training from epoch 3020 with loss: 0.0014649800723418593\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Zhenyu\\AppData\\Local\\Temp\\ipykernel_26000\\2958448606.py:8: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(checkpoint_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3030, Loss: 0.0013\n",
      "Epoch 3040, Loss: 0.0010\n",
      "Epoch 3050, Loss: 0.0010\n",
      "Epoch 3060, Loss: 0.0008\n",
      "Epoch 3070, Loss: 0.0042\n",
      "Epoch 3080, Loss: 0.0188\n",
      "Epoch 3090, Loss: 0.0091\n",
      "Epoch 3100, Loss: 0.0060\n",
      "Epoch 3110, Loss: 0.0031\n",
      "Epoch 3120, Loss: 0.0037\n",
      "Epoch 3130, Loss: 0.0055\n",
      "Epoch 3140, Loss: 0.0057\n",
      "Epoch 3150, Loss: 0.0021\n",
      "Epoch 3160, Loss: 0.0019\n",
      "Epoch 3170, Loss: 0.0015\n",
      "Epoch 3180, Loss: 0.0012\n",
      "Epoch 3190, Loss: 0.0010\n",
      "Epoch 3200, Loss: 0.0143\n",
      "Epoch 3210, Loss: 0.0124\n",
      "Epoch 3220, Loss: 0.0092\n",
      "Epoch 3230, Loss: 0.0053\n",
      "Epoch 3240, Loss: 0.0025\n",
      "Epoch 3250, Loss: 0.0019\n",
      "Epoch 3260, Loss: 0.0015\n",
      "Epoch 3270, Loss: 0.0012\n",
      "Epoch 3280, Loss: 0.0013\n",
      "Epoch 3290, Loss: 0.0016\n",
      "Epoch 3300, Loss: 0.0039\n",
      "Epoch 3310, Loss: 0.0037\n",
      "Epoch 3320, Loss: 0.0029\n",
      "Epoch 3330, Loss: 0.0017\n",
      "Epoch 3340, Loss: 0.0014\n",
      "Epoch 3350, Loss: 0.0011\n",
      "Epoch 3360, Loss: 0.0010\n",
      "Epoch 3370, Loss: 0.0009\n",
      "Epoch 3380, Loss: 0.0009\n",
      "Epoch 3390, Loss: 0.0294\n",
      "Epoch 3400, Loss: 0.0149\n",
      "Epoch 3410, Loss: 0.0084\n",
      "Epoch 3420, Loss: 0.0059\n",
      "Epoch 3430, Loss: 0.0112\n",
      "Epoch 3440, Loss: 0.0052\n",
      "Epoch 3450, Loss: 0.0059\n",
      "Epoch 3460, Loss: 0.0033\n",
      "Epoch 3470, Loss: 0.0022\n",
      "Epoch 3480, Loss: 0.0016\n",
      "Epoch 3490, Loss: 0.0013\n",
      "Epoch 3500, Loss: 0.0012\n",
      "Epoch 3510, Loss: 0.0016\n",
      "Epoch 3520, Loss: 0.0014\n",
      "Epoch 3530, Loss: 0.0012\n",
      "Epoch 3540, Loss: 0.0054\n",
      "Epoch 3550, Loss: 0.0063\n",
      "Epoch 3560, Loss: 0.0022\n",
      "Epoch 3570, Loss: 0.0020\n",
      "Epoch 3580, Loss: 0.0014\n",
      "Epoch 3590, Loss: 0.0010\n",
      "Epoch 3600, Loss: 0.0012\n",
      "Epoch 3610, Loss: 0.0016\n",
      "Epoch 3620, Loss: 0.0046\n",
      "Epoch 3630, Loss: 0.0023\n",
      "Epoch 3640, Loss: 0.0016\n",
      "Epoch 3650, Loss: 0.0012\n",
      "Epoch 3660, Loss: 0.0010\n",
      "Epoch 3670, Loss: 0.0014\n",
      "Epoch 3680, Loss: 0.0010\n",
      "Epoch 3690, Loss: 0.0186\n",
      "Epoch 3700, Loss: 0.0080\n",
      "Epoch 3710, Loss: 0.0210\n",
      "Epoch 3720, Loss: 0.0119\n",
      "Epoch 3730, Loss: 0.0053\n",
      "Epoch 3740, Loss: 0.0034\n",
      "Epoch 3750, Loss: 0.0023\n",
      "Epoch 3760, Loss: 0.0152\n",
      "Epoch 3770, Loss: 0.0132\n",
      "Epoch 3780, Loss: 0.0047\n",
      "Epoch 3790, Loss: 0.0023\n",
      "Epoch 3800, Loss: 0.0017\n",
      "Epoch 3810, Loss: 0.0012\n",
      "Epoch 3820, Loss: 0.0009\n",
      "Epoch 3830, Loss: 0.0009\n",
      "Epoch 3840, Loss: 0.0115\n",
      "Epoch 3850, Loss: 0.0162\n",
      "Epoch 3860, Loss: 0.0074\n",
      "Epoch 3870, Loss: 0.0043\n",
      "Epoch 3880, Loss: 0.0028\n",
      "Epoch 3890, Loss: 0.0023\n",
      "Epoch 3900, Loss: 0.0018\n",
      "Epoch 3910, Loss: 0.0014\n",
      "Epoch 3920, Loss: 0.0012\n",
      "Epoch 3930, Loss: 0.0013\n",
      "Epoch 3940, Loss: 0.0031\n",
      "Epoch 3950, Loss: 0.0030\n",
      "Epoch 3960, Loss: 0.0067\n",
      "Epoch 3970, Loss: 0.0030\n",
      "Epoch 3980, Loss: 0.0017\n",
      "Epoch 3990, Loss: 0.0013\n",
      "Epoch 4000, Loss: 0.0012\n",
      "Epoch 4010, Loss: 0.0010\n",
      "Epoch 4020, Loss: 0.0014\n",
      "Condition 1 satisfied: B(x) >= 0 for all x in X_s\n",
      "Condition 2 violated: B(x) is non-negative for some x in X_u\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Zhenyu\\AppData\\Local\\Temp\\ipykernel_26000\\4037616741.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  state_tensor = torch.tensor(state, dtype=torch.float32)\n",
      "C:\\Users\\Zhenyu\\AppData\\Local\\Temp\\ipykernel_26000\\4037616741.py:18: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
      "  grid_state = state + np.array([dx] * len(state))  # Add dx to each dimension of state\n",
      "C:\\Users\\Zhenyu\\AppData\\Local\\Temp\\ipykernel_26000\\3396284254.py:5: DeprecationWarning: __array__ implementation doesn't accept a copy keyword, so passing copy=False failed. __array__ must implement 'dtype' and 'copy' keyword arguments. To learn more, see the migration guide https://numpy.org/devdocs/numpy_2_0_migration_guide.html#adapting-to-changes-in-the-copy-keyword\n",
      "  state = np.array(state)\n",
      "C:\\Users\\Zhenyu\\AppData\\Local\\Temp\\ipykernel_26000\\3396284254.py:17: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
      "  state_next = state_detached + delta_t * dynamics_model(state_detached.numpy(), control_input)  # Use detached state\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Condition 3 violated: for len of 0\n",
      "no violating states\n",
      "goood enough\n"
     ]
    }
   ],
   "source": [
    "cond1 = verify_safe_states(barrier_net, states_safe)\n",
    "cond2 =  verify_unsafe_states(barrier_net, states_unsafe)\n",
    "\n",
    "\n",
    "for i in range(10):\n",
    "    count = 0\n",
    "    if os.path.exists(checkpoint_path):\n",
    "        checkpoint = torch.load(checkpoint_path)\n",
    "        barrier_net.load_state_dict(checkpoint['model_state_dict'])\n",
    "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "        start_epoch = checkpoint['epoch'] + 1  # Continue from the next epoch\n",
    "        print(f\"Resuming training from epoch {start_epoch} with loss: {checkpoint['loss']}\")\n",
    "    for epoch in range(start_epoch, start_epoch+1000):\n",
    "        # Forward pass: Compute B(x) for safe and unsafe states\n",
    "        B_s = barrier_net(states_safe)\n",
    "        B_u = barrier_net(states_unsafe)\n",
    "\n",
    "        # Compute Lf B(x) approximation for safe states\n",
    "        Lf_B_s = compute_Lf_B_approx(barrier_net, states_safe, next_states_safe, delta_t)\n",
    "\n",
    "        # Compute the loss\n",
    "        loss = barrier_loss(B_s, B_u, Lf_B_s, gamma, ws, wu, wl)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            print(f\"Epoch {epoch + 1}, Loss: {loss.item():.4f}\")\n",
    "\n",
    "        # Save model and optimizer state every 10 epochs\n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            torch.save({\n",
    "                'epoch': epoch,  # current epoch\n",
    "                'model_state_dict': barrier_net.state_dict(),  # model parameters\n",
    "                'optimizer_state_dict': optimizer.state_dict(),  # optimizer parameters\n",
    "                'loss': loss.item(),  # last loss value\n",
    "            }, checkpoint_path)\n",
    "\n",
    "    # Condition 1: Verify safe states\n",
    "    cond1 = verify_safe_states(barrier_net, states_safe)\n",
    "\n",
    "    # Condition 2: Verify unsafe states\n",
    "    cond2 = verify_unsafe_states(barrier_net, states_unsafe)\n",
    "\n",
    "    # Condition 3: Verify Lie derivative for boundary states\n",
    "    grid_states = create_grid_around_boundary(states_safe, threshold=0.1, delta=0.05)\n",
    "    violating_states = verify_lie_derivative(barrier_net, grid_states, dynamics_model)\n",
    "\n",
    "    training_states = np.vstack([states_safe, states_unsafe])  # Stack them together\n",
    "    training_labels = np.array([1] * len(states_safe) + [0] * len(states_unsafe))  # Safe = 1, Unsafe = 0\n",
    "\n",
    "    # Convert violating states into a NumPy array\n",
    "    violating_states_np = np.array([state.detach().numpy() for state in violating_states])\n",
    "\n",
    "\n",
    "    # Use kNN to predict the labels for the violating states\n",
    "    if violating_states_np.size > 0:\n",
    "        violating_labels = knn_labeling(training_states, training_labels, violating_states_np)\n",
    "    else:\n",
    "        print(\"no violating states\")\n",
    "    \n",
    "    if cond1:\n",
    "        count+=1\n",
    "    if cond2:\n",
    "        count+=1\n",
    "    if violating_states_np.size == 0:\n",
    "        count+=1\n",
    "    if count > 1:\n",
    "        print(\"goood enough\")\n",
    "        break\n",
    "\n",
    "    # Print out the labels for violating states\n",
    "    # for i, state in enumerate(violating_states):\n",
    "    #     print(f\"State {state}: Label {violating_labels[i]}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NCBF_IHI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
